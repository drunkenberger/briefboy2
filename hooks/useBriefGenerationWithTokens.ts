import { useEffect, useState } from 'react';
import { knowledgeBaseService } from '../services/knowledgeBaseService';
import { useTokenTracking, extractOpenAITokenUsage, estimateClaudeTokens, estimateGeminiTokens } from './useTokenTracking';

// [Same SYSTEM_PROMPT and buildUserPrompt as original - truncated for brevity]
const SYSTEM_PROMPT = `Eres Elena Rodr√≠guez, una Directora de Marketing experimentada con m√°s de 15 a√±os de experiencia en agencias top como Ogilvy, BBDO y TBWA. Tu tarea es CREAR un Brief de Marketing integral (no analizar uno existente) a partir de una transcripci√≥n de reuni√≥n.

BASE DE CONOCIMIENTO - MEJORES PR√ÅCTICAS DE BRIEFS:
${knowledgeBaseService.getAllKnowledge()}

Bas√°ndote en esta base de conocimiento, aseg√∫rate de que tu brief siga las mejores pr√°cticas de la industria y evite errores comunes.

**IMPORTANTE:** NO est√°s analizando un brief existente. Est√°s CREANDO un nuevo brief de marketing desde cero bas√°ndote en la transcripci√≥n.

**TU TAREA:**
1. Leer la transcripci√≥n de una reuni√≥n/discusi√≥n de marketing
2. Extraer informaci√≥n clave sobre la campa√±a/proyecto
3. CREAR un Brief de Marketing completo con todas las secciones llenas
4. Usar tu experiencia en marketing para llenar cualquier vac√≠o

**EST√ÅNDARES PROFESIONALES:**
*   Crear insights accionables y recomendaciones espec√≠ficas y medibles
*   Llenar cualquier vac√≠o estrat√©gico con recomendaciones profesionales basadas en las mejores pr√°cticas de la industria
*   Asegurar que TODOS los campos en la salida JSON est√©n poblados con contenido detallado y espec√≠fico
*   NUNCA dejar campos vac√≠os - siempre proporcionar contenido integral para cada campo
*   Si falta informaci√≥n en la transcripci√≥n, usa tu experiencia en marketing para crear ejemplos con contenido realista pero informa al usuario que falta informaci√≥n
*   **ESCRIBIR TODO EL CONTENIDO EN ESPA√ëOL** - Todos los textos, descripciones, objetivos y recomendaciones deben estar en espa√±ol

**FORMATO DE SALIDA:**
Responde √öNICAMENTE con un objeto JSON v√°lido en la siguiente estructura integral. No incluyas texto adicional, explicaciones o formato markdown. TODO EL CONTENIDO DEL JSON DEBE ESTAR EN ESPA√ëOL.

{
  "projectTitle": "Nombre espec√≠fico de la campa√±a o proyecto",
  "briefSummary": "Resumen ejecutivo de 2-3 oraciones describiendo el objetivo y estrategia de la campa√±a",
  "businessChallenge": "Descripci√≥n detallada del principal desaf√≠o empresarial que esta campa√±a debe resolver",
  "strategicObjectives": [
    "Objetivo empresarial espec√≠fico y medible 1",
    "Objetivo empresarial espec√≠fico y medible 2",
    "Objetivo empresarial espec√≠fico y medible 3"
  ],
  "targetAudience": {
    "primary": "Descripci√≥n detallada de la audiencia objetivo primaria incluyendo demograf√≠a, psicograf√≠a, comportamientos y necesidades",
    "secondary": "Descripci√≥n de audiencia secundaria (si aplica)",
    "insights": [
      "Insight clave sobre la audiencia 1",
      "Insight clave sobre la audiencia 2",
      "Insight clave sobre la audiencia 3"
    ]
  },
  "brandPositioning": "Declaraci√≥n clara de c√≥mo la marca se posiciona en el mercado y en la mente de los consumidores",
  "creativeStrategy": {
    "bigIdea": "El punto de partida creativo que guiar√° toda la campa√±a",
    "messageHierarchy": [
      "Mensaje principal",
      "Mensaje secundario de apoyo",
      "Mensaje terciario/CTA"
    ],
    "toneAndManner": "Descripci√≥n de c√≥mo debe sonar y sentirse la comunicaci√≥n",
    "creativeMandatories": [
      "Elemento obligatorio 1 (logo, tagline, etc.)",
      "Elemento obligatorio 2"
    ]
  },
  "channelStrategy": {
    "recommendedMix": [
      {
        "channel": "Nombre del canal (ej: Instagram)",
        "allocation": "% o cantidad de presupuesto",
        "rationale": "Por qu√© este canal",
        "kpis": ["KPI 1", "KPI 2"]
      }
    ],
    "integratedApproach": "C√≥mo trabajar√°n todos los canales juntos de manera integrada"
  },
  "successMetrics": {
    "primary": [
      "KPI primario 1 (ej: 20% aumento en conocimiento de marca)",
      "KPI primario 2"
    ],
    "secondary": [
      "KPI secundario 1",
      "KPI secundario 2"
    ],
    "measurementFramework": "C√≥mo se medir√° y rastrear√° el √©xito"
  },
  "budgetConsiderations": {
    "estimatedRange": "Rango total de presupuesto (ej: $100K-$150K)",
    "keyInvestments": [
      "√Årea de inversi√≥n principal 1",
      "√Årea de inversi√≥n principal 2"
    ],
    "costOptimization": [
      "Estrategia de optimizaci√≥n de costos 1",
      "Estrategia de optimizaci√≥n de costos 2"
    ]
  },
  "riskAssessment": {
    "risks": [
      {
        "risk": "Descripci√≥n del riesgo",
        "likelihood": "Alto/Medio/Bajo",
        "impact": "Alto/Medio/Bajo",
        "mitigation": "Estrategia de mitigaci√≥n"
      }
    ]
  },
  "implementationRoadmap": {
    "phases": [
      {
        "phase": "Fase 1: Planificaci√≥n",
        "duration": "2 semanas",
        "deliverables": ["Entregable 1", "Entregable 2"],
        "dependencies": ["Dependencia 1"]
      }
    ]
  },
  "nextSteps": [
    "Pr√≥ximo paso inmediato 1",
    "Pr√≥ximo paso 2",
    "Pr√≥ximo paso 3"
  ],
  "appendix": {
    "assumptions": [
      "Suposici√≥n clave 1",
      "Suposici√≥n clave 2"
    ],
    "references": [
      "Referencia o fuente 1",
      "Referencia o fuente 2"
    ]
  }
}`;

function buildUserPrompt(transcription: string) {
  return `**SOLICITUD DE CREACI√ìN DE BRIEF DE MARKETING**

Bas√°ndote en la siguiente transcripci√≥n de reuni√≥n, CREA un Brief de Marketing integral desde cero:

---
"${transcription}"
---

**INSTRUCCIONES:**
Esta transcripci√≥n contiene discusiones sobre una campa√±a/proyecto de marketing. Tu trabajo es CREAR (no analizar) un Brief de Marketing completo mediante:

1. **Extraer informaci√≥n clave** de la transcripci√≥n sobre:
   - Detalles de la campa√±a/proyecto
   - Objetivos y desaf√≠os empresariales
   - Insights de audiencia objetivo
   - Posicionamiento de marca y mensajer√≠a
   - Preferencias de canales y presupuesto
   - Cronograma y m√©tricas de √©xito

2. **Crear contenido completo** para cada secci√≥n del brief:
   - Escribir descripciones detalladas, no solo puntos clave
   - Proporcionar recomendaciones espec√≠ficas y accionables
   - Llenar vac√≠os con tu experiencia en marketing pero informa al usuario que falta informaci√≥n y que est√°s agregando ejemplos con contenido realista
   - Hacerlo listo para producci√≥n

3. **Entregar un brief completo** que los equipos de marketing puedan usar inmediatamente

**RECUERDA:** Est√°s CREANDO un nuevo Brief de Marketing, no analizando uno existente. Genera contenido integral para cada campo bas√°ndote en la transcripci√≥n y tu experiencia profesional.

**IMPORTANTE: TODO EL CONTENIDO DE TU RESPUESTA DEBE ESTAR EN ESPA√ëOL. Escribe todos los textos, descripciones, objetivos, recomendaciones y contenido del brief completamente en espa√±ol.**`;
}

interface UseBriefGenerationResult {
  brief: any | null;
  loading: boolean;
  error: string | null;
  tokensUsed: number;
  tokensBreakdown: Record<string, number>;
  estimatedCost: number;
}

/**
 * Hook para generar un brief publicitario a partir de un transcript usando OpenAI con tracking de tokens.
 * @param transcript Texto transcrito de la reuni√≥n
 * @param enabled Si es true, inicia la generaci√≥n autom√°ticamente
 * @returns { brief, loading, error, tokensUsed, tokensBreakdown, estimatedCost }
 */
export function useBriefGenerationWithTokens(
  transcript: string | null, 
  enabled: boolean = true
): UseBriefGenerationResult {
  const [brief, setBrief] = useState<any | null>(null);
  const [loading, setLoading] = useState(false);
  const [error, setError] = useState<string | null>(null);
  const [tokensUsed, setTokensUsed] = useState(0);
  const [tokensBreakdown, setTokensBreakdown] = useState<Record<string, number>>({});
  const [estimatedCost, setEstimatedCost] = useState(0);
  
  const { countTokens, trackTokenUsage, calculateCost } = useTokenTracking();

  useEffect(() => {
    if (!transcript || !enabled) return;
    let cancelled = false;
    
    // Verificar que al menos una API key est√© disponible
    const openaiKey = process.env.EXPO_PUBLIC_OPENAI_API_KEY;
    const claudeKey = process.env.EXPO_PUBLIC_CLAUDE_API_KEY;
    const geminiKey = process.env.EXPO_PUBLIC_GEMINI_API_KEY;

    if (!openaiKey && !claudeKey && !geminiKey) {
      setError('No se encontr√≥ ninguna API key configurada (OpenAI, Claude o Gemini)');
      setLoading(false);
      setBrief(null);
      return;
    }

    console.log('[BriefGenerationWithTokens] APIs disponibles:', {
      openai: !!openaiKey,
      claude: !!claudeKey,
      gemini: !!geminiKey
    });

    const generateBrief = async () => {
      try {
        setLoading(true);
        setError(null);
        setBrief(null);
        setTokensUsed(0);
        setTokensBreakdown({});
        setEstimatedCost(0);
        
        // Count input tokens
        const systemPromptTokens = countTokens(SYSTEM_PROMPT);
        const userPromptTokens = countTokens(buildUserPrompt(transcript));
        const totalInputTokens = systemPromptTokens + userPromptTokens;
        
        console.log('[BriefGenerationWithTokens] Token counts:', {
          systemPrompt: systemPromptTokens,
          userPrompt: userPromptTokens,
          totalInput: totalInputTokens
        });
        
        // Intentar con m√∫ltiples modelos como respaldo
        let response;
        let responseData: any = null;
        let lastError;
        let modelUsed = '';
        let outputTokens = 0;

        // Primer intento: OpenAI GPT-4o-mini (m√°s r√°pido y barato)
        if (openaiKey) {
          try {
            console.log('ü§ñ Intentando generar brief con OpenAI GPT-4o-mini...');
            modelUsed = 'gpt-4o-mini';
            
            // Create abort controller with 15 second timeout
            const abortController = new AbortController();
            const timeoutId = setTimeout(() => {
              console.warn('‚è∞ OpenAI request timeout after 15 seconds');
              abortController.abort();
            }, 15000);
            
            response = await fetch('https://api.openai.com/v1/chat/completions', {
              method: 'POST',
              headers: {
                'Content-Type': 'application/json',
                'Authorization': `Bearer ${openaiKey}`,
              },
              body: JSON.stringify({
                model: 'gpt-4o-mini',
                messages: [
                  { role: 'system', content: SYSTEM_PROMPT },
                  { role: 'user', content: buildUserPrompt(transcript) },
                ],
                temperature: 0.2,
                max_tokens: 3000,
                response_format: { type: "json_object" },
              }),
              signal: abortController.signal,
            });
            
            // Clear timeout if request completes successfully
            clearTimeout(timeoutId);

            if (response.ok) {
              console.log('‚úÖ OpenAI GPT-4o-mini funcion√≥ correctamente');
              const data = await response.json();
              responseData = data;
              
              // Extract token usage from OpenAI response
              const usage = extractOpenAITokenUsage(data);
              if (usage) {
                outputTokens = usage.output_tokens || 0;
                const totalTokens = (usage.total_tokens || 0);
                const cost = calculateCost('gpt-4o-mini', usage.input_tokens || totalInputTokens, outputTokens);
                
                trackTokenUsage({
                  service: 'gpt4_generation',
                  model: 'gpt-4o-mini',
                  input_tokens: usage.input_tokens || totalInputTokens,
                  output_tokens: outputTokens,
                  total_tokens: totalTokens,
                  estimated_cost: cost
                });
                
                setTokensUsed(totalTokens);
                setTokensBreakdown({
                  gpt4_generation: totalTokens,
                  total: totalTokens
                });
                setEstimatedCost(cost);
              }
            } else {
              const errorText = await response.text();
              console.error('OpenAI API Error:', response.status, errorText);
              throw new Error(`Error de OpenAI (${response.status})`);
            }
          } catch (openaiError: any) {
            // Handle timeout specifically
            if (openaiError.name === 'AbortError') {
              console.warn('‚ö†Ô∏è OpenAI timeout despu√©s de 15 segundos');
              lastError = new Error('OpenAI timeout');
            } else {
              console.warn('‚ö†Ô∏è OpenAI fall√≥:', openaiError);
              lastError = openaiError;
            }
          }
        }

        // Segundo intento: Claude (solo si no hay respuesta exitosa)
        if (!response?.ok && claudeKey) {
          try {
            console.log('ü§ñ Intentando generar brief con Claude...');
            modelUsed = 'claude-3-haiku';
            
            // Create abort controller with 15 second timeout
            const abortController = new AbortController();
            const timeoutId = setTimeout(() => {
              console.warn('‚è∞ Claude request timeout after 15 seconds');
              abortController.abort();
            }, 15000);
            
            response = await fetch('https://api.anthropic.com/v1/messages', {
              method: 'POST',
              headers: {
                'Content-Type': 'application/json',
                'x-api-key': claudeKey,
                'anthropic-version': '2023-06-01',
              },
              body: JSON.stringify({
                model: 'claude-3-haiku-20240307',
                max_tokens: 3000,
                messages: [
                  { role: 'user', content: `${SYSTEM_PROMPT}\n\n${buildUserPrompt(transcript)}` },
                ],
                temperature: 0.2,
              }),
              signal: abortController.signal,
            });
            
            // Clear timeout if request completes successfully
            clearTimeout(timeoutId);

            if (response.ok) {
              console.log('‚úÖ Claude funcion√≥ correctamente');
              const data = await response.json();
              responseData = data;
              
              // Estimate Claude tokens
              const outputText = data.content?.[0]?.text || '';
              outputTokens = countTokens(outputText);
              const totalTokens = totalInputTokens + outputTokens;
              const cost = calculateCost('claude-3-haiku', totalInputTokens, outputTokens);
              
              trackTokenUsage({
                service: 'claude_generation',
                model: 'claude-3-haiku',
                input_tokens: totalInputTokens,
                output_tokens: outputTokens,
                total_tokens: totalTokens,
                estimated_cost: cost
              });
              
              setTokensUsed(totalTokens);
              setTokensBreakdown({
                claude_generation: totalTokens,
                total: totalTokens
              });
              setEstimatedCost(cost);
            } else {
              const errorText = await response.text();
              console.error('Claude API Error:', response.status, errorText);
              throw new Error(`Error de Claude (${response.status})`);
            }
          } catch (claudeError: any) {
            // Handle timeout specifically
            if (claudeError.name === 'AbortError') {
              console.warn('‚ö†Ô∏è Claude timeout despu√©s de 15 segundos');
              lastError = new Error('Claude timeout');
            } else {
              console.warn('‚ö†Ô∏è Claude fall√≥:', claudeError);
              lastError = claudeError;
            }
          }
        }

        // Tercer intento: Gemini (solo si no hay respuesta exitosa)
        if (!response?.ok && geminiKey) {
          try {
            console.log('ü§ñ Intentando generar brief con Gemini...');
            modelUsed = 'gemini-1.5-flash';
            
            // Create abort controller with 15 second timeout
            const abortController = new AbortController();
            const timeoutId = setTimeout(() => {
              console.warn('‚è∞ Gemini request timeout after 15 seconds');
              abortController.abort();
            }, 15000);
            
            response = await fetch(
              `https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash-latest:generateContent?key=${geminiKey}`,
              {
                method: 'POST',
                headers: {
                  'Content-Type': 'application/json',
                },
                body: JSON.stringify({
                  contents: [{
                    parts: [{
                      text: `${SYSTEM_PROMPT}\n\n${buildUserPrompt(transcript)}`
                    }]
                  }],
                  generationConfig: {
                    temperature: 0.2,
                    maxOutputTokens: 3000,
                  },
                }),
                signal: abortController.signal,
              }
            );
            
            // Clear timeout if request completes successfully
            clearTimeout(timeoutId);

            if (response.ok) {
              console.log('‚úÖ Gemini funcion√≥ correctamente');
              const data = await response.json();
              responseData = data;
              
              // Estimate Gemini tokens
              const outputText = data.candidates?.[0]?.content?.parts?.[0]?.text || '';
              outputTokens = countTokens(outputText);
              const totalTokens = totalInputTokens + outputTokens;
              const cost = calculateCost('gemini-1.5-flash', totalInputTokens, outputTokens);
              
              trackTokenUsage({
                service: 'gemini_generation',
                model: 'gemini-1.5-flash',
                input_tokens: totalInputTokens,
                output_tokens: outputTokens,
                total_tokens: totalTokens,
                estimated_cost: cost
              });
              
              setTokensUsed(totalTokens);
              setTokensBreakdown({
                gemini_generation: totalTokens,
                total: totalTokens
              });
              setEstimatedCost(cost);
            } else {
              const errorText = await response.text();
              console.error('Gemini API Error:', response.status, errorText);
              throw new Error(`Error de Gemini (${response.status})`);
            }
          } catch (geminiError: any) {
            // Handle timeout specifically
            if (geminiError.name === 'AbortError') {
              console.warn('‚ö†Ô∏è Gemini timeout despu√©s de 15 segundos');
              lastError = new Error('Gemini timeout');
            } else {
              console.warn('‚ö†Ô∏è Gemini fall√≥:', geminiError);
              lastError = geminiError;
            }
          }
        }

        // Verificar si todos los intentos fallaron
        if (!response?.ok) {
          console.error('‚ùå Todos los modelos de IA fallaron');
          // Log detailed error for debugging (server-side only)
          if (lastError) {
            console.error('Detalles del √∫ltimo error:', lastError);
          }
          // Throw generic error message without sensitive details
          throw new Error('Todos los modelos de IA fallaron');
        }

        console.log('[BriefGenerationWithTokens] ‚úÖ Respuesta exitosa recibida');
        console.log('[BriefGenerationWithTokens] Modelo usado:', modelUsed);
        
        let content = '';

        // Extraer contenido seg√∫n el modelo usado
        if (responseData.choices && responseData.choices[0]?.message?.content) {
          // OpenAI response
          content = responseData.choices[0].message.content;
        } else if (responseData.content && responseData.content[0]?.text) {
          // Claude response
          content = responseData.content[0].text;
        } else if (responseData.candidates && responseData.candidates[0]?.content?.parts?.[0]?.text) {
          // Gemini response
          content = responseData.candidates[0].content.parts[0].text;
        }

        if (!content) {
          console.error('[BriefGenerationWithTokens] Error cr√≠tico: No hay contenido');
          throw new Error('No se recibi√≥ contenido v√°lido de ning√∫n modelo');
        }

        // Parse and validate the content as in the original hook
        let parsed: any = null;
        try {
          console.log('[BriefGenerationWithTokens] Intentando parsear JSON...');

          // Limpiar el contenido primero
          let cleanContent = content.trim();

          // Remover markdown code blocks si existen
          cleanContent = cleanContent.replace(/```json\n?/g, '').replace(/```\n?/g, '');

          // Buscar el JSON v√°lido
          const jsonStart = cleanContent.indexOf('{');
          const jsonEnd = cleanContent.lastIndexOf('}');

          if (jsonStart !== -1 && jsonEnd !== -1 && jsonEnd > jsonStart) {
            cleanContent = cleanContent.substring(jsonStart, jsonEnd + 1);
          }

          parsed = JSON.parse(cleanContent);
          console.log('[BriefGenerationWithTokens] JSON parseado exitosamente:', Object.keys(parsed));

          // Validar que NO es un an√°lisis (detectar si contiene campos de an√°lisis)
          const analysisFields = ['overallScore', 'completenessScore', 'qualityScore', 'strengths', 'weaknesses', 'criticalIssues', 'sectionAnalysis'];
          const isAnalysis = analysisFields.some(field => parsed.hasOwnProperty(field));

          if (isAnalysis) {
            console.error('[BriefGenerationWithTokens] ‚ùå IA devolvi√≥ un an√°lisis en lugar de un brief');
            throw new Error("La IA devolvi√≥ un an√°lisis del brief en lugar de crear un brief. Reintentando...");
          }

        } catch (e: any) {
          console.error('[BriefGenerationWithTokens] Error parseando JSON:', e.message);
          
          if (!cancelled) setBrief({
            projectTitle: '‚ö†Ô∏è Error en generaci√≥n de brief',
            briefSummary: 'Ocurri√≥ un error al procesar la respuesta de la IA. Por favor, intenta nuevamente con una transcripci√≥n m√°s clara.',
            businessChallenge: 'La respuesta de la IA no pudo ser procesada correctamente, posiblemente debido a un formato de respuesta inv√°lido.',
            strategicObjectives: [
              'Revisar la transcripci√≥n de entrada',
              'Verificar la claridad del contenido',
              'Intentar nuevamente con una transcripci√≥n m√°s espec√≠fica'
            ],
            targetAudience: {
              primary: 'Usuario que experimenta dificultades t√©cnicas con la generaci√≥n del brief',
              secondary: 'Equipo de soporte t√©cnico',
              insights: [
                'El usuario necesita una respuesta clara sobre el problema',
                'La transcripci√≥n original puede necesitar mejoras',
                'Se requiere una soluci√≥n alternativa o reintento'
              ]
            },
            brandPositioning: 'Herramienta de generaci√≥n de briefs confiable que busca resolver problemas t√©cnicos de manera transparente',
            creativeStrategy: {
              bigIdea: 'Transparencia y soluci√≥n proactiva de problemas t√©cnicos',
              messageHierarchy: [
                'Ha ocurrido un error t√©cnico que estamos manejando',
                'Te proporcionamos informaci√≥n clara sobre qu√© sali√≥ mal',
                'Puedes intentar nuevamente con mejores resultados'
              ],
              toneAndManner: 'Profesional, transparente y orientado a la soluci√≥n',
              creativeMandatories: [
                'Mensaje de error claro y comprensible',
                'Instrucciones de recuperaci√≥n espec√≠ficas'
              ]
            },
            channelStrategy: {
              recommendedMix: [
                {
                  channel: 'Interfaz de usuario',
                  allocation: '100%',
                  rationale: 'Canal directo para comunicar el error al usuario',
                  kpis: ['Claridad del mensaje', 'Tasa de resoluci√≥n exitosa']
                }
              ],
              integratedApproach: 'Comunicaci√≥n directa y transparente a trav√©s de la interfaz de usuario con opciones claras de recuperaci√≥n'
            },
            successMetrics: {
              primary: [
                'Usuario entiende el problema y sabe c√≥mo proceder',
                'Reducci√≥n en frustraciones t√©cnicas del usuario'
              ],
              secondary: [
                'Mejora en la calidad de transcripciones futuras',
                'Aumento en intentos exitosos posteriores'
              ],
              measurementFramework: 'Seguimiento de errores t√©cnicos y tasas de resoluci√≥n exitosa'
            },
            budgetConsiderations: {
              estimatedRange: 'Costo de tiempo del usuario y recursos de soporte',
              keyInvestments: [
                'Mejoras en el manejo de errores',
                'Optimizaci√≥n del procesamiento de IA'
              ],
              costOptimization: [
                'Prevenci√≥n proactiva de errores similares',
                'Mejora en la validaci√≥n de respuestas de IA'
              ]
            },
            riskAssessment: {
              risks: [
                {
                  risk: 'Frustraci√≥n del usuario por errores t√©cnicos',
                  likelihood: 'Medio',
                  impact: 'Alto',
                  mitigation: 'Proporcionar mensajes claros y opciones de recuperaci√≥n'
                },
                {
                  risk: 'P√©rdida de confianza en la herramienta',
                  likelihood: 'Medio',
                  impact: 'Alto',
                  mitigation: 'Transparencia total y soluciones r√°pidas'
                }
              ]
            },
            implementationRoadmap: {
              phases: [
                {
                  phase: 'Fase 1: Reintento inmediato',
                  duration: 'Inmediato',
                  deliverables: ['Nueva transcripci√≥n', 'Par√°metros ajustados'],
                  dependencies: ['Transcripci√≥n mejorada del usuario']
                },
                {
                  phase: 'Fase 2: An√°lisis del problema',
                  duration: '1 d√≠a',
                  deliverables: ['Diagn√≥stico del error', 'Plan de mejora'],
                  dependencies: ['Logs de error detallados']
                }
              ]
            },
            nextSteps: [
              'Revisar la transcripci√≥n original y verificar su claridad',
              'Intentar nuevamente con una transcripci√≥n m√°s espec√≠fica',
              'Contactar soporte si el problema persiste'
            ],
            appendix: {
              assumptions: [
                'La transcripci√≥n original contiene informaci√≥n v√°lida',
                'El error es temporal y resoluble',
                'El usuario puede proporcionar una transcripci√≥n alternativa'
              ],
              references: [
                'Logs de error del sistema',
                'Documentaci√≥n de mejores pr√°cticas para transcripciones',
                'Gu√≠a de resoluci√≥n de problemas t√©cnicos'
              ]
            }
          });
          setLoading(false);
          return;
        }

        // Si el JSON es v√°lido, mostrar el brief generado
        console.log('[BriefGenerationWithTokens] ‚úÖ Brief generado exitosamente');
        if (!cancelled) {
          setBrief(parsed);
        }
      } catch (e: any) {
        console.error('[BriefGenerationWithTokens] Error de red/fetch:', e);
        // Set generic error message without exposing sensitive details
        setError('Error de conexi√≥n. Intenta nuevamente.');
        setBrief({ _raw: 'Error de conexi√≥n' });
        setLoading(false);
      } finally {
        if (!cancelled) setLoading(false);
      }
    };

    generateBrief();
    return () => { cancelled = true; };
  }, [transcript, enabled, countTokens, trackTokenUsage, calculateCost]);

  return { brief, loading, error, tokensUsed, tokensBreakdown, estimatedCost };
}